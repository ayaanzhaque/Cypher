{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 4 # length (in seconds) of input\n",
    "desired_sr = 16000 # sampling rate to use\n",
    "mic_sr = 16000 # rate supported by Sampling library like PDM\n",
    "desired_samples = max_length*desired_sr # total number of samples in input\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "os.environ['PYTHONHASHSEED'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing the data\n",
    "dataset_min = 0.0\n",
    "dataset_max = 1.0\n",
    "\n",
    "def denormalize_dataset(input_val):\n",
    "  global dataset_min, dataset_max\n",
    "  return input_val * (dataset_max - dataset_min)\n",
    "\n",
    "#Function to normalize input values\n",
    "def normalize_dataset(input_val):\n",
    "  global dataset_min, dataset_max\n",
    "  dataset_min = np.min(input_val) \n",
    "  dataset_max = np.max(input_val) \n",
    "\n",
    "  diff = dataset_max - dataset_min\n",
    "  if (diff != 0):\n",
    "    input_val /= diff\n",
    "  return input_val\n",
    "\n",
    "def interpolateAudio(audio):\n",
    "    factor = float(mic_sr)/desired_sr\n",
    "    x_interp_values = []\n",
    "    for i in range(len(audio)):\n",
    "        x_interp_values.append(int(factor*i))\n",
    "    audio_interpolated = np.interp(range(int(len(audio)*factor)), x_interp_values, audio)\n",
    "\n",
    "    return mic_sr, audio_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_noise = False # add different words, null samples and random noise\n",
    "n_classes = len(hotwords) + int(add_noise) \n",
    "\n",
    "class_nSamples = 1000 # number of samples in the hotword classes\n",
    "other_nSamples = float(class_nSamples)/(len(word_dirs) - n_classes) # number of samples to be picked from each of the non-hotword classes\n",
    "\n",
    "def nLabel(word):\n",
    "    return n_classes-1 if ( word not in hotwords ) else hotwords.index(word)\n",
    "\n",
    "def textLabel(index):\n",
    "    return hotwords[index] if index <len(hotwords) else \"background\"\n",
    "\n",
    "def sampleBackGround():\n",
    "    return add_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset storing audio samples for wake word and background\n",
    "\n",
    "top_dir = 'audio'\n",
    "\n",
    "input_audio   = np.empty((0, desired_samples)).astype(np.float32)\n",
    "input_labels  = np.empty((0)).astype(np.int32); # index of the word in hotwords list is the lable.\n",
    "\n",
    "for word in (word_dirs) :\n",
    "    print(\"\\n\",word)\n",
    "    \n",
    "    if ( word not in hotwords and False == sampleBackGround()) : # background, do not include\n",
    "        print(\"-- Background/noise/other words not included\")\n",
    "        continue\n",
    "        \n",
    "    else: # to be included\n",
    "        dfx = df[df['class'] == word]\n",
    "        start_time = time.time()\n",
    "\n",
    "        wav_files = 0\n",
    "\n",
    "        word_samples = np.empty((0, desired_samples))\n",
    "        \n",
    "        if word in hotwords: # hotwords\n",
    "            print(\"-- Category : hotword\")\n",
    "            \n",
    "            for i in range(len(dfx)):\n",
    "                file_path = top_dir + \"/fold\" + str(dfx.iloc[i]['fold']) + \"/\" + str(dfx.iloc[i]['slice_file_name'])\n",
    "\n",
    "                X_sub = np.empty((0, desired_samples))\n",
    "                X, sr = librosa.core.load(file_path, sr=desired_sr)\n",
    "                X, interval = librosa.effects.trim(X)\n",
    "\n",
    "                if X.shape[0] < desired_sr: # if samples less than 1 second\n",
    "                    continue\n",
    "\n",
    "                if X.shape[0]%desired_samples != 0: # if it needs padding, else, there will be unnecessary silence appended\n",
    "                    X = np.pad(X, (0, desired_samples - (X.shape[0]%desired_samples)))\n",
    "                \n",
    "                X_sub = np.array(np.split(X, int(X.shape[0]*1.0/desired_samples)))\n",
    "                \n",
    "                word_samples = np.append(word_samples, X_sub, axis=0)\n",
    "\n",
    "                if ( word_samples.shape[0] > class_nSamples ):\n",
    "                    break\n",
    "\n",
    "                wav_files = wav_files + 1\n",
    "            \n",
    "        else:\n",
    "            print(\"-- Category : backgound/noise/other words\")\n",
    "\n",
    "            for i in range(len(dfx)):\n",
    "                file_path = top_dir + \"/fold\" + str(dfx.iloc[i]['fold']) + \"/\" + str(dfx.iloc[i]['slice_file_name'])\n",
    "                X_sub = np.empty((0, desired_samples))\n",
    "                X, sr = librosa.core.load(file_path, sr=desired_sr)\n",
    "                X, interval = librosa.effects.trim(X)\n",
    "\n",
    "                if X.shape[0] < desired_sr: # if samples less than 1 second\n",
    "                    continue\n",
    "\n",
    "                if X.shape[0]%desired_samples != 0: # if it needs padding, else, there will be unnecessary silence appended\n",
    "                    X = np.pad(X, (0, desired_samples - (X.shape[0]%desired_samples)))\n",
    "                \n",
    "                X_sub = np.array(np.split(X, int(X.shape[0]*1.0/desired_samples)))\n",
    "                \n",
    "                word_samples = np.append(word_samples, X_sub, axis=0)\n",
    "\n",
    "                if ( word_samples.shape[0] > other_nSamples ):\n",
    "                    break\n",
    "                \n",
    "                wav_files = wav_files + 1\n",
    "            \n",
    "        if ( word_samples.size > 0 ):\n",
    "            input_audio = np.concatenate((input_audio, word_samples), axis=0)\n",
    "            labels = np.full((word_samples.shape[0]), nLabel(word))\n",
    "            input_labels = np.concatenate((input_labels, labels))\n",
    "\n",
    "            print(\"added {} audio files with {} samples for word \\\"{}\\\" with label {} in {:.1f} sec.\".\n",
    "                  format(wav_files, labels.shape[0], word, nLabel(word), (time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_labels = np.zeros((input_labels.size, n_classes)).astype(np.int32)\n",
    "onehot_labels[np.arange(input_labels.size), input_labels] = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
