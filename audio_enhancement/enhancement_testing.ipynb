{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os.path\n",
    "import time\n",
    "import ipdb\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import SENN\n",
    "import audio_reader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log10_fac = 1 / np.log(10)\n",
    "\n",
    "\n",
    "def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor\n",
    "    (for TensorBoard visualization).\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        tensor_name = var.op.name\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.scalar_summary(tensor_name + 'mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.scalar_summary(tensor_name + 'stddev', stddev)\n",
    "        tf.scalar_summary(tensor_name + 'max', tf.reduce_max(var))\n",
    "        tf.scalar_summary(tensor_name + 'min', tf.reduce_min(var))\n",
    "        tf.histogram_summary(tensor_name + 'histogram', var)\n",
    "\n",
    "\n",
    "def conv2d(x, W):\n",
    "    '''1 dimentional convolution difined in the paper\n",
    "    the function's name is not appropriate and\n",
    "    we didn't change that'''\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 100, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "class SE_NET(object):\n",
    "    \"\"\"Class:speech enhancement net\"\"\"\n",
    "    def __init__(self, batch_size, NEFF, N_IN, N_OUT, DECAY=0.999):\n",
    "        '''NEFF: number of effective FFT points\n",
    "        N_IN: number of input frames into the nets\n",
    "        N_OUT: only tested for 1, errors may occur for other number\n",
    "        DECAY: decay for global mean and var estimation using batch norm\n",
    "        '''\n",
    "        self.batch_size = batch_size\n",
    "        self.NEFF = NEFF\n",
    "        self.N_IN = N_IN\n",
    "        self.N_OUT = N_OUT\n",
    "        self.DECAY = DECAY\n",
    "\n",
    "    def inputs(self, raw_data_batch):\n",
    "        '''transform the raw data_batch into\n",
    "        the input for the nets\n",
    "        it runs really fast and we don't need to store\n",
    "        all the mixed samples'''\n",
    "        # ipdb.set_trace()\n",
    "        # transpose for FFT\n",
    "        # shape:\n",
    "        # batch, N_IN, 2, frame_length to 2 batch N_in frame_length\n",
    "        raw_data_batch_t = tf.transpose(raw_data_batch, [2, 0, 1, 3])\n",
    "        raw_data = raw_data_batch_t[0][:][:][:]\n",
    "        raw_speech = raw_data_batch_t[1][:][:][:]\n",
    "\n",
    "        # FFT\n",
    "        # shape:\n",
    "        # batch, N_in, NFFT\n",
    "        data_f0 = tf.fft(tf.cast(raw_data, tf.complex64))\n",
    "        # shape:\n",
    "        # NFFT, batch, N_in\n",
    "        data_f1 = tf.transpose(data_f0, [2, 0, 1])\n",
    "        data_f2 = data_f1[0:self.NEFF][:][:]\n",
    "        # shape:\n",
    "        # batch, N_in, NEFF\n",
    "        data_f3 = tf.transpose(data_f2, [1, 2, 0])\n",
    "        data_f4 = tf.square(tf.real(data_f3)) + tf.square(tf.imag(data_f3))\n",
    "        # limiting the minimum value\n",
    "        data_f5 = tf.maximum(data_f4, 1e-10)\n",
    "        # into log spectrum\n",
    "        data_f = 10 * tf.log(data_f5 * 10000) * log10_fac\n",
    "        # same operational for reference speech\n",
    "        speech_f0 = tf.fft(tf.cast(raw_speech, tf.complex64))\n",
    "        speech_f1 = tf.transpose(speech_f0, [2, 0, 1])\n",
    "        speech_f2 = speech_f1[0:self.NEFF][:][:]\n",
    "        speech_f3 = tf.transpose(speech_f2, [1, 2, 0])\n",
    "        speech_f4 = tf.square(\n",
    "            tf.real(speech_f3)) + tf.square(tf.imag(speech_f3))\n",
    "        speech_f5 = tf.maximum(speech_f4, 1e-10)\n",
    "        speech_f = 10 * tf.log(speech_f5 * 10000) * log10_fac\n",
    "\n",
    "        # shape:\n",
    "        # batch, N_in, NEFF\n",
    "        images = data_f\n",
    "        targets = tf.concat(\n",
    "            0,\n",
    "            [tf.reshape(\n",
    "                speech_f[i][self.N_IN - 1][0:self.NEFF],\n",
    "                [1, self.NEFF])\n",
    "             for i in range(0, self.batch_size, 1)])\n",
    "        # do per image whitening (not batch normalization!)\n",
    "        images_reshape = tf.transpose(tf.reshape(\n",
    "            images, [self.batch_size, -1]))\n",
    "        targets_reshape = tf.transpose(tf.reshape(\n",
    "            targets, [self.batch_size, -1]))\n",
    "        batch_mean, batch_var = tf.nn.moments(images_reshape, [0])\n",
    "        images_reshape_norm = tf.nn.batch_normalization(\n",
    "            images_reshape, batch_mean, batch_var, 0, 1, 1e-10)\n",
    "        targets_reshape_norm = tf.nn.batch_normalization(\n",
    "            targets_reshape, batch_mean, batch_var, 0, 1, 1e-10)\n",
    "        # ipdb.set_trace()\n",
    "        images_norm = tf.reshape(tf.transpose(images_reshape_norm),\n",
    "                                 [self.batch_size, self.N_IN, self.NEFF])\n",
    "        targets_norm = tf.reshape(tf.transpose(targets_reshape_norm),\n",
    "                                  [self.batch_size, self.NEFF])\n",
    "        return images_norm, targets_norm\n",
    "\n",
    "    def _batch_norm_wrapper(self, inputs, is_trianing, epsilon=1e-6):\n",
    "        '''wrap up all the operations needed for batch norm\n",
    "        is_training: true -> using batch property\n",
    "                     false -> using global(population) property'''\n",
    "        decay = self.DECAY\n",
    "        scale = tf.Variable(tf.ones(inputs.get_shape()[-1]))\n",
    "        beta = tf.Variable(tf.zeros(inputs.get_shape()[-1]))\n",
    "\n",
    "        # population mean and var\n",
    "        pop_mean = tf.Variable(\n",
    "            tf.zeros([inputs.get_shape()[-1]]), trainable=False)\n",
    "        pop_var = tf.Variable(\n",
    "            tf.ones([inputs.get_shape()[-1]]), trainable=False)\n",
    "        if is_trianing:\n",
    "            batch_mean, batch_var = tf.nn.moments(inputs, [0, 1, 2])\n",
    "            # update estimation\n",
    "            train_mean = tf.assign(pop_mean,\n",
    "                                   pop_mean * decay +\n",
    "                                   batch_mean * (1 - decay))\n",
    "            train_var = tf.assign(pop_var,\n",
    "                                  pop_var * decay +\n",
    "                                  batch_var * (1 - decay))\n",
    "            with tf.control_dependencies([train_mean, train_var]):\n",
    "                return tf.nn.batch_normalization(\n",
    "                    inputs, batch_mean, batch_var, beta, scale, epsilon)\n",
    "        else:\n",
    "            return tf.nn.batch_normalization(\n",
    "                inputs, pop_mean, pop_var, beta, scale, epsilon)\n",
    "\n",
    "    def _conv_layer_wrapper(self,\n",
    "                            input, out_feature_maps, filter_length, is_train):\n",
    "        '''wrap up all the ops for convolution'''\n",
    "        filter_width = input.get_shape()[1].value\n",
    "        in_feature_maps = input.get_shape()[-1].value\n",
    "        W_conv = weight_variable(\n",
    "            [filter_width, filter_length, in_feature_maps, out_feature_maps])\n",
    "        b_conv = bias_variable([out_feature_maps])\n",
    "        h_conv_t = conv2d(input, W_conv) + b_conv\n",
    "        # use batch norm\n",
    "        h_conv_b = self._batch_norm_wrapper(h_conv_t, is_train)\n",
    "        return tf.nn.relu(h_conv_b)\n",
    "\n",
    "    def inference(self, images, is_train):\n",
    "        '''Net configuration as the original paper'''\n",
    "        image_input = tf.reshape(images, [-1, self.N_IN, self.NEFF, 1])\n",
    "        # ipdb.set_trace()\n",
    "        with tf.variable_scope('con1') as scope:\n",
    "            h_conv1 = self._conv_layer_wrapper(image_input, 12, 13, is_train)\n",
    "        with tf.variable_scope('con2') as scope:\n",
    "            h_conv2 = self._conv_layer_wrapper(h_conv1, 16, 11, is_train)\n",
    "        with tf.variable_scope('con3') as scope:\n",
    "            h_conv3 = self._conv_layer_wrapper(h_conv2, 20, 9, is_train)\n",
    "        with tf.variable_scope('con4') as scope:\n",
    "            h_conv4 = self._conv_layer_wrapper(h_conv3, 24, 7, is_train)\n",
    "        with tf.variable_scope('con5') as scope:\n",
    "            h_conv5 = self._conv_layer_wrapper(h_conv4, 32, 7, is_train)\n",
    "        with tf.variable_scope('con6') as scope:\n",
    "            h_conv6 = self._conv_layer_wrapper(h_conv5, 24, 7, is_train)\n",
    "        with tf.variable_scope('con7') as scope:\n",
    "            h_conv7 = self._conv_layer_wrapper(h_conv6, 20, 9, is_train)\n",
    "        with tf.variable_scope('con8') as scope:\n",
    "            h_conv8 = self._conv_layer_wrapper(h_conv7, 16, 11, is_train)\n",
    "        with tf.variable_scope('con9') as scope:\n",
    "            h_conv9 = self._conv_layer_wrapper(h_conv8, 12, 13, is_train)\n",
    "        with tf.variable_scope('con10') as scope:\n",
    "            f_w = h_conv9.get_shape()[1].value\n",
    "            i_fm = h_conv9.get_shape()[-1].value\n",
    "            W_con10 = weight_variable(\n",
    "                [f_w, 129, i_fm, 1])\n",
    "            b_conv10 = bias_variable([1])\n",
    "            h_conv10 = conv2d(h_conv9, W_con10) + b_conv10\n",
    "        return tf.reshape(h_conv10, [-1, self.NEFF])\n",
    "\n",
    "    def loss(self, inf_targets, targets):\n",
    "        '''l2 loss for the log spectrum'''\n",
    "        loss_v = tf.nn.l2_loss(inf_targets - targets) / self.batch_size\n",
    "        tf.scalar_summary('loss', loss_v)\n",
    "        # loss_merge = tf.cond(\n",
    "        #     is_val, lambda: tf.scalar_summary('val_loss_batch', loss_v),\n",
    "        #     lambda: tf.scalar_summary('loss', loss_v))\n",
    "        return loss_v\n",
    "        # return tf.reduce_mean(tf.nn.l2_loss(inf_targets - targets))\n",
    "\n",
    "    def train(self, loss, lr):\n",
    "        '''optimizer'''\n",
    "        # optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "        optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=lr,\n",
    "            beta1=0.9,\n",
    "            beta2=0.999,\n",
    "            epsilon=1e-8)\n",
    "        train_op = optimizer.minimize(loss)\n",
    "        return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
